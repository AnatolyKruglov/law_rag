#!/usr/bin/env python3
"""
Main script to run the RAG pipeline with multiple sources
"""

import sys
import os
import time
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.data.document_loader import DocumentLoader
from src.processing.text_splitter import TextSplitter, DocumentType
from src.processing.embeddings import EmbeddingManager
from src.retrieval.vector_store import VectorStoreManager
from src.generation.qa_chain import QASystem
from src.utils.helpers import setup_logging, format_sources, analyze_document_stats
from config.settings import settings, SearchMode

def analyze_documents(documents):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —á–∞–Ω–∫–∏–Ω–≥–∞"""
    if not documents:
        return None
    
    pptx_docs = [doc for doc in documents if doc.metadata.get('type') == 'pptx']
    consultant_docs = [doc for doc in documents if doc.metadata.get('type') != 'pptx']
    
    stats = {
        'total': len(documents),
        'pptx_count': len(pptx_docs),
        'consultant_count': len(consultant_docs),
        'avg_pptx_length': 0,
        'avg_consultant_length': 0
    }
    
    if pptx_docs:
        total_length = sum(len(doc.page_content) for doc in pptx_docs)
        stats['avg_pptx_length'] = total_length / len(pptx_docs)
    
    if consultant_docs:
        total_length = sum(len(doc.page_content) for doc in consultant_docs)
        stats['avg_consultant_length'] = total_length / len(consultant_docs)
    
    # print(f"\nüìä –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:")
    # print(f"   –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {stats['total']}")
    # print(f"   PPTX –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {stats['pptx_count']}")
    # print(f"   –ö–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç+ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {stats['consultant_count']}")
    
    # if stats['pptx_count'] > 0:
    #     print(f"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ PPTX: {stats['avg_pptx_length']:.0f} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # if stats['consultant_count'] > 0:
    #     print(f"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ö–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç+: {stats['avg_consultant_length']:.0f} —Å–∏–º–≤–æ–ª–æ–≤")
    
    return stats

def main(questions):
    setup_logging()
    
    try:        
        if settings.SEARCH_MODE == SearchMode.CONSULTANT_ONLY:
            print("üìÑ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ Consultant Plus")
            loader = DocumentLoader(use_consultant_plus=True, use_pptx=False)
            document_type = DocumentType.CONSULTANT
        elif settings.SEARCH_MODE == SearchMode.PPTX_ONLY:
            print("üìä –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ PPTX —Ñ–∞–π–ª—ã")
            loader = DocumentLoader(use_consultant_plus=False, use_pptx=True)
            document_type = DocumentType.PPTX
        else:  # BOTH
            print("üîó –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –æ–±–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞: Consultant Plus –∏ PPTX —Ñ–∞–π–ª—ã")
            loader = DocumentLoader(use_consultant_plus=True, use_pptx=True)
            document_type = DocumentType.MIXED
        
        for question in questions:
            print(f"‚ùì –í–æ–ø—Ä–æ—Å: {question}")
            
            # 1. Load documents from configured sources
            print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
            documents = loader.load_documents_from_query(question)
            
            if not documents:
                print("‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ –¥–∞–Ω–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É")
                continue
                
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            stats = analyze_documents(documents)
            
            # 2. Split documents —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
            print("‚úÇÔ∏è  –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            splitter = TextSplitter(document_type=document_type)
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            recommendations = splitter.get_optimal_settings(
                document_type.value,
                stats['avg_pptx_length'] if stats else None
            )
            
            # print(f"   –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:")
            # print(f"   - –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞: {recommendations['chunk_size']}")
            # print(f"   - –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ: {recommendations['chunk_overlap']}")
            # print(f"   - –°—Ç—Ä–∞—Ç–µ–≥–∏—è: {recommendations['strategy']}")
            # print(f"   - –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: {recommendations['reasoning']}")
            
            chunks = splitter.split_documents(documents)
            # print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤ –∏–∑ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —á–∞–Ω–∫–æ–≤
            if chunks:
                avg_chunk_size = sum(len(chunk.page_content) for chunk in chunks) / len(chunks)
                min_chunk = min(len(chunk.page_content) for chunk in chunks)
                max_chunk = max(len(chunk.page_content) for chunk in chunks)
                
                # print(f"   –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —á–∞–Ω–∫–æ–≤:")
                # print(f"   - –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä: {avg_chunk_size:.0f} —Å–∏–º–≤–æ–ª–æ–≤")
                # print(f"   - –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π: {min_chunk} —Å–∏–º–≤–æ–ª–æ–≤")
                # print(f"   - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π: {max_chunk} —Å–∏–º–≤–æ–ª–æ–≤")
                
                # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –µ—Å–ª–∏ —á–∞–Ω–∫–∏ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ –∏–ª–∏ –º–∞–ª–µ–Ω—å–∫–∏–µ
                if avg_chunk_size > 2500:
                    print("   ‚ö†Ô∏è  –ß–∞–Ω–∫–∏ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–º–µ–Ω—å—à–∏—Ç—å CHUNK_SIZE")
                elif avg_chunk_size < 500:
                    print("   ‚ö†Ô∏è  –ß–∞–Ω–∫–∏ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–≤–µ–ª–∏—á–∏—Ç—å CHUNK_SIZE")
            
            # 3. Create embeddings and vector store with retry logic
            print("üß† –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞...")
            embedding_manager = EmbeddingManager()
            embeddings = embedding_manager.get_embeddings()
            
            vector_manager = VectorStoreManager(embeddings)
            
            # Add retry logic for vector store creation
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω—å—à–∏–π batch_size –¥–ª—è PPTX
                    batch_size = 2 if document_type == DocumentType.PPTX else 3
                    vector_store = vector_manager.create_vector_store(chunks, batch_size=batch_size)
                    break
                except Exception as e:
                    if "rate quota limit exceed" in str(e) and attempt < max_retries - 1:
                        wait_time = (attempt + 1) * 15  # 15, 30, 45 seconds
                        print(f"‚è≥ –õ–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤, –∂–¥–µ–º {wait_time} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π {attempt + 1}/{max_retries}")
                        time.sleep(wait_time)
                        continue
                    else:
                        raise
            
            # 4. Create QA system
            print("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è QA —Å–∏—Å—Ç–µ–º—ã...")
            retriever = vector_manager.get_retriever()
            qa_system = QASystem(retriever)
            
            # 5. Make query         
            result = qa_system.query(question)
            
            print(f"\nüìù –û—Ç–≤–µ—Ç:")
            print(result['answer'])
            
            print(f"\nüìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏:")
            print(format_sources(result['source_documents']))
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ: {e}")
        raise

if __name__ == "__main__":
    main(
        questions=[
            "—Ç—Ä—É–¥–æ–≤–æ–π –∫–æ–¥–µ–∫—Å –æ—Ç–ø—É—Å–∫",
        ],
    )