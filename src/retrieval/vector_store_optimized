from langchain.vectorstores import FAISS
from langchain.schema import Document
from typing import List
import logging
import time

logger = logging.getLogger(__name__)

class OptimizedVectorStoreManager:
    """Optimized vector store manager with very conservative rate limiting"""
    
    def __init__(self, embeddings):
        self.embeddings = embeddings
        self.vector_store = None
    
    def create_vector_store(self, documents: List[Document]):
        """Create vector store with very conservative settings"""
        try:
            logger.info(f"Creating vector store with {len(documents)} documents")
            
            # Use FAISS's built-in batch processing with custom rate limiting
            self.vector_store = FAISS.from_documents(
                documents, 
                self.embeddings,
                batch_size=2,  # Very small batch size
                rate_limiter={
                    'requests_per_second': 2,  # Very conservative
                    'batch_wait_time': 1.0
                }
            )
            
            logger.info("Vector store created successfully")
            return self.vector_store
            
        except Exception as e:
            logger.error(f"Error creating vector store: {e}")
            # Fallback: try one document at a time
            return self._create_slow_vector_store(documents)
    
    def _create_slow_vector_store(self, documents: List[Document]):
        """Fallback method - process one document at a time"""
        logger.info("Using fallback slow vector store creation")
        
        if not documents:
            raise ValueError("No documents to process")
        
        # Start with first document
        self.vector_store = FAISS.from_documents([documents[0]], self.embeddings)
        logger.info(f"Added 1/{len(documents)} documents")
        
        # Add remaining documents one by one with delays
        for i in range(1, len(documents)):
            time.sleep(2)  # 2 second delay between each document
            self.vector_store.add_documents([documents[i]])
            logger.info(f"Added {i+1}/{len(documents)} documents")
        
        return self.vector_store
    
    def get_retriever(self, search_type: str = "similarity", **kwargs):
        """Get retriever from vector store"""
        if not self.vector_store:
            raise ValueError("Vector store not initialized")
        
        from config.settings import settings
        search_kwargs = {**settings.SEARCH_KWARGS, **kwargs}
        return self.vector_store.as_retriever(
            search_type=search_type,
            search_kwargs=search_kwargs
        )