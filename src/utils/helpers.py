import logging
from typing import List
import faiss

def setup_logging(level=logging.INFO):
    """Setup logging configuration"""
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞ Faiss
    faiss_logger = logging.getLogger('faiss')
    faiss_logger.setLevel(logging.WARNING)  # –¢–æ–ª—å–∫–æ WARNING –∏ –≤—ã—à–µ
    faiss_logger.propagate = False  # –ù–µ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –≤—ã—à–µ
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ loader –æ—Ç–¥–µ–ª—å–Ω–æ
    faiss_loader_logger = logging.getLogger('faiss.loader')
    faiss_loader_logger.setLevel(logging.ERROR)  # –¢–æ–ª—å–∫–æ ERROR –∏ –≤—ã—à–µ
    faiss_loader_logger.propagate = False
    
    # –û—Å–Ω–æ–≤–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('rag_pipeline.log')
        ]
    )
    
    # –û—Ç–∫–ª—é—á–∞–µ–º –ª–∏—à–Ω–∏–µ –ª–æ–≥–∏ –æ—Ç –¥—Ä—É–≥–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
    logging.getLogger('httpx').setLevel(logging.WARNING)
    logging.getLogger('httpcore').setLevel(logging.WARNING)
    logging.getLogger('urllib3').setLevel(logging.WARNING)
    logging.getLogger('requests').setLevel(logging.WARNING)

def format_sources(source_documents: List) -> str:
    """Format source documents for display"""
    if not source_documents:
        return "No sources found"
    
    sources = []
    consultant_count = 0
    pptx_count = 0
    other_count = 0
    
    for i, doc in enumerate(source_documents, 1):
        source_info = f"üîó –ò—Å—Ç–æ—á–Ω–∏–∫ {i}:"
        
        if hasattr(doc, 'metadata'):
            # Determine source type
            source_type = doc.metadata.get('type', 'unknown')
            chunk_type = doc.metadata.get('chunk_type', 'standard')
            
            if 'consultant' in doc.metadata.get('source', '').lower() or source_type == 'consultant':
                source_type_display = "–ö–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ü–ª—é—Å"
                consultant_count += 1
            elif source_type == 'pptx' or doc.metadata.get('source', '').endswith('.pptx'):
                source_type_display = "PPTX"
                pptx_count += 1
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–ª–∞–π–¥–µ –¥–ª—è PPTX
                if 'slide_number' in doc.metadata:
                    source_type_display += f" (–°–ª–∞–π–¥ {doc.metadata['slide_number']})"
                elif 'slide_numbers' in doc.metadata:
                    source_type_display += f" (–°–ª–∞–π–¥—ã {doc.metadata['slide_numbers']})"
                
                if chunk_type != 'standard':
                    source_type_display += f" [{chunk_type}]"
            else:
                source_type_display = "–î—Ä—É–≥–æ–π"
                other_count += 1
            
            source_info += f" {source_type_display}"
            
            if 'source' in doc.metadata:
                # Shorten long paths
                source = doc.metadata['source']
                if len(source) > 80:
                    if '\\' in source:
                        # –î–ª—è Windows –ø—É—Ç–µ–π –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∏–º—è —Ñ–∞–π–ª–∞
                        filename = source.split('\\')[-1]
                        source_info += f" - {filename}"
                    else:
                        source_info += f" - ...{source[-60:]}"
                else:
                    source_info += f" - {source}"
            
            if 'title' in doc.metadata and doc.metadata['title']:
                title = doc.metadata['title'][:40]
                if len(doc.metadata['title']) > 40:
                    title += "..."
                source_info += f" - {title}"
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞
            if hasattr(doc, 'page_content'):
                source_info += f" ({len(doc.page_content)} —Å–∏–º–≤–æ–ª–æ–≤)"
        
        sources.append(source_info)
    
    # Add summary
    summary = f"\nüìä –ò—Ç–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: –ö–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ü–ª—é—Å - {consultant_count}, PPTX - {pptx_count}, –¥—Ä—É–≥–∏–µ - {other_count}"
    sources.append(summary)
    
    return "\n".join(sources)

def analyze_document_stats(documents: List) -> dict:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —á–∞–Ω–∫–∏–Ω–≥—É"""
    if not documents:
        return {}
    
    stats = {
        'total_documents': len(documents),
        'total_characters': 0,
        'avg_length': 0,
        'min_length': float('inf'),
        'max_length': 0,
        'type_distribution': {},
        'recommendations': []
    }
    
    for doc in documents:
        content_length = len(doc.page_content)
        stats['total_characters'] += content_length
        stats['min_length'] = min(stats['min_length'], content_length)
        stats['max_length'] = max(stats['max_length'], content_length)
        
        doc_type = doc.metadata.get('type', 'unknown')
        if doc_type not in stats['type_distribution']:
            stats['type_distribution'][doc_type] = 0
        stats['type_distribution'][doc_type] += 1
    
    stats['avg_length'] = stats['total_characters'] / len(documents) if documents else 0
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    if stats['avg_length'] < 1000:
        stats['recommendations'].append("–î–æ–∫—É–º–µ–Ω—Ç—ã –∫–æ—Ä–æ—Ç–∫–∏–µ. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—å—à–∏–µ —á–∞–Ω–∫–∏ (800-1200 —Å–∏–º–≤–æ–ª–æ–≤).")
    elif stats['avg_length'] > 5000:
        stats['recommendations'].append("–î–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª–∏–Ω–Ω—ã–µ. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±√≥–ª—å—à–∏–µ —á–∞–Ω–∫–∏ (3000-4000 —Å–∏–º–≤–æ–ª–æ–≤).")
    
    pptx_count = stats['type_distribution'].get('pptx', 0)
    if pptx_count > 0:
        stats['recommendations'].append(f"–ù–∞–π–¥–µ–Ω–æ {pptx_count} PPTX —Ñ–∞–π–ª–æ–≤. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —á–∞–Ω–∫–∏–Ω–≥–∞ –ø–æ —Å–ª–∞–π–¥–∞–º.")
    
    return stats